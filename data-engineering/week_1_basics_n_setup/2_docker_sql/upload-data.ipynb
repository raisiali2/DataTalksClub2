{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc509f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1357eded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "760078f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# panad is a convient way of dealing with tabular data csv file is tabular data thats why we are going to use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03e7587d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('2021_Yellow_Taxi_Trip_Data.csv', nrows = 100)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ccf44df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tpep_pickup_datetime = pd.to_datetime(df.tpep_pickup_datetime)\n",
    "df.tpep_dropoff_datetime = pd.to_datetime(df.tpep_dropoff_datetime)\n",
    "# now we parsed these two columns as datetime and write back to data frame  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a99ea01c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28997248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create connection to postgres\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bea81571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next take this dataset and put it to our postgres for that we need first generate schema as instruction like create \n",
    "# table specify what types of columns are there and so on for that import a module called ioa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71ccfd23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE \"yellow_taxi_data\" (\n",
      "\"VendorID\" INTEGER,\n",
      "  \"tpep_pickup_datetime\" TEXT,\n",
      "  \"tpep_dropoff_datetime\" TEXT,\n",
      "  \"passenger_count\" INTEGER,\n",
      "  \"trip_distance\" REAL,\n",
      "  \"RatecodeID\" INTEGER,\n",
      "  \"store_and_fwd_flag\" TEXT,\n",
      "  \"PULocationID\" INTEGER,\n",
      "  \"DOLocationID\" INTEGER,\n",
      "  \"payment_type\" INTEGER,\n",
      "  \"fare_amount\" REAL,\n",
      "  \"extra\" REAL,\n",
      "  \"mta_tax\" REAL,\n",
      "  \"tip_amount\" REAL,\n",
      "  \"tolls_amount\" REAL,\n",
      "  \"improvement_surcharge\" REAL,\n",
      "  \"total_amount\" REAL,\n",
      "  \"congestion_surcharge\" REAL\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(pd.io.sql.get_schema(df, name='yellow_taxi_data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d7c768e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE \"yellow_taxi_data\" (\n",
      "\"VendorID\" INTEGER,\n",
      "  \"tpep_pickup_datetime\" TIMESTAMP,\n",
      "  \"tpep_dropoff_datetime\" TIMESTAMP,\n",
      "  \"passenger_count\" INTEGER,\n",
      "  \"trip_distance\" REAL,\n",
      "  \"RatecodeID\" INTEGER,\n",
      "  \"store_and_fwd_flag\" TEXT,\n",
      "  \"PULocationID\" INTEGER,\n",
      "  \"DOLocationID\" INTEGER,\n",
      "  \"payment_type\" INTEGER,\n",
      "  \"fare_amount\" REAL,\n",
      "  \"extra\" REAL,\n",
      "  \"mta_tax\" REAL,\n",
      "  \"tip_amount\" REAL,\n",
      "  \"tolls_amount\" REAL,\n",
      "  \"improvement_surcharge\" REAL,\n",
      "  \"total_amount\" REAL,\n",
      "  \"congestion_surcharge\" REAL\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# from above statement we see that those two columns was a text now we re run the above statement to check if those columns\n",
    "# changed to timestamp or not\n",
    "print(pd.io.sql.get_schema(df, name='yellow_taxi_data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81ad2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# those above two columsn tpep_pickup_datetime\" TIMESTAMP and \"tpep_dropoff_datetime\" TIMESTAMP changed to timestamp\n",
    "# now we need to generate DDL statement by creating table statement something that postgres understand.\n",
    "# for that we need to tell pandas that we need to put in postgres then it will generate statements that works for postgres\n",
    "# for that we need to create a connection to postgres and then it will generate statement specifically for postgres\n",
    "# for creating this connection panda use a library called \"SQLAlchemy\" for dealing with SQL. if you have anaconda it is \n",
    "# already installed otherwise use \"pip install sqlalchemy\" to install it\n",
    "# for my case i check in the data-eng-venv i have or no if no i use pip to install it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e74de370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af3f8c96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# in engine we need to specify the type of database => user=> password=> hostname=>port=>database name\n",
    "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b774f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as i get the error \"No module named 'psycopg2'\"\n",
    "# question it must install within docker containder? or in \"data-eng-venv\"? is it important where we install it?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22b981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "36c5d8fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.base.Connection at 0x7fa2df730f10>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9901f5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE yellow_taxi_data (\n",
      "\t\"VendorID\" BIGINT, \n",
      "\ttpep_pickup_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\ttpep_dropoff_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tpassenger_count BIGINT, \n",
      "\ttrip_distance FLOAT(53), \n",
      "\t\"RatecodeID\" BIGINT, \n",
      "\tstore_and_fwd_flag TEXT, \n",
      "\t\"PULocationID\" BIGINT, \n",
      "\t\"DOLocationID\" BIGINT, \n",
      "\tpayment_type BIGINT, \n",
      "\tfare_amount FLOAT(53), \n",
      "\textra FLOAT(53), \n",
      "\tmta_tax FLOAT(53), \n",
      "\ttip_amount FLOAT(53), \n",
      "\ttolls_amount FLOAT(53), \n",
      "\timprovement_surcharge FLOAT(53), \n",
      "\ttotal_amount FLOAT(53), \n",
      "\tcongestion_surcharge FLOAT(53)\n",
      ")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(pd.io.sql.get_schema(df, name='yellow_taxi_data'))\n",
    "# now we need to specify the connectiontion that we have created\n",
    "print(pd.io.sql.get_schema(df, name='yellow_taxi_data', con=engine))\n",
    "# now we have definition in postgres dialac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9212979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we are ready with the data\n",
    "# as the entire dataset is more than one milion so we dont need to insert all the data at once to our database ande\n",
    "# we dont know how our database react we are going to chunk the data using pandas iterator and insert chunk csv file to\n",
    "# small dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c7b134c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk csv file to smaller data frame using iterator = True then choose chuck size by getting help press \n",
    "# \"shift+tab\"\n",
    "df_iter = pd.read_csv('2021_Yellow_Taxi_Trip_Data.csv', iterator=True, chunksize=100000)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da55e1f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.io.parsers.readers.TextFileReader at 0x7fa2dfc245b0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if i print it it shows that it is not an data frame but it is an iterator\n",
    "df_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a0cd9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now for taking first chunk we use the below code\n",
    "df = next(df_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "814a548c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the size of this df\n",
    "len(df)\n",
    "# the size of this df is exactly 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b55658ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be sure that it is time stamp we use the below code\n",
    "df.tpep_pickup_datetime = pd.to_datetime(df.tpep_pickup_datetime)\n",
    "df.tpep_dropoff_datetime = pd.to_datetime(df.tpep_dropoff_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "773ed3e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return only first 5 records\n",
    "# df.head()\n",
    "# if we specify n= 1 it returns only first record\n",
    "# i want create a table first on column name but not insert the data\n",
    "df.head(n=0).to_sql(name='yellow_taxi_data', con=engine, if_exists='replace')\n",
    "# executed succesfully\n",
    "# now i go docker container \"pgcli\" check what kinds of table we have\n",
    "# raisi@raisi-ThinkPad-E14-Gen-4:~/datascience-prj/DataTalksClub/data-engineering/week_1_basics_n_setup/2_docker_sql$ pgcli -h localhost -p 5432 -u root -d ny_taxi\n",
    "\n",
    "# root@localhost:ny_taxi> \\dt\n",
    "# now \\dt in pgcli return the name of table \n",
    "# +--------+------------------+-------+-------+\n",
    "# | Schema | Name             | Type  | Owner |\n",
    "# |--------+------------------+-------+-------|\n",
    "# | public | yellow_taxi_data | table | root  |\n",
    "# +--------+------------------+-------+-------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dfacc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also describe the table using below code\n",
    "# root@localhost:ny_taxi>  \\d yellow_taxi_data\n",
    "# it return the below information\n",
    "# +-----------------------+-----------------------------+-----------+\n",
    "# | Column                | Type                        | Modifiers |\n",
    "# |-----------------------+-----------------------------+-----------|\n",
    "# | index                 | bigint                      |           |\n",
    "# | VendorID              | bigint                      |           |\n",
    "# | tpep_pickup_datetime  | timestamp without time zone |           |\n",
    "# | tpep_dropoff_datetime | timestamp without time zone |           |\n",
    "# | passenger_count       | bigint                      |           |\n",
    "# | trip_distance         | double precision            |           |\n",
    "# | RatecodeID            | bigint                      |           |\n",
    "# | store_and_fwd_flag    | text                        |           |\n",
    "# | PULocationID          | bigint                      |           |\n",
    "# | DOLocationID          | bigint                      |           |\n",
    "# | payment_type          | bigint                      |           |\n",
    "# | fare_amount           | double precision            |           |\n",
    "# | extra                 | double precision            |           |\n",
    "# | mta_tax               | double precision            |           |\n",
    "# | tip_amount            | double precision            |           |\n",
    "# | tolls_amount          | double precision            |           |\n",
    "# | improvement_surcharge | double precision            |           |\n",
    "# :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd5a917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from above we saw the schema that we have created\n",
    "# now we are going to put some data in this table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b549f1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.54 s, sys: 13.9 ms, total: 2.55 s\n",
      "Wall time: 4.81 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we use if_exists='append' we use it for inserting each chunk of data to the existen table\n",
    "# use \"%time\" to tell us how much time it take to insert the data\n",
    "%time df.to_sql(name='yellow_taxi_data', con=engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64d142c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk inserted succesfully now going to pgcli to get count of inserted data using below query\n",
    "# root@localhost:ny_taxi> select COUNT(1) from yellow_taxi_data\n",
    "# result:\n",
    "# +--------+\n",
    "# | count  |\n",
    "# |--------|\n",
    "# | 100000 |\n",
    "# +--------+\n",
    "# SELECT 1\n",
    "# Time: 0.019s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c542f2a5",
   "metadata": {},
   "source": [
    "# now we insert the rest of dataset to our table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "42b371ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to know how much time it will took we use\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047c3405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserted another chunk...., took 14.222 second\n",
      "inserted another chunk...., took 14.121 second\n",
      "inserted another chunk...., took 13.899 second\n",
      "inserted another chunk...., took 14.120 second\n",
      "inserted another chunk...., took 13.933 second\n",
      "inserted another chunk...., took 13.898 second\n",
      "inserted another chunk...., took 14.064 second\n",
      "inserted another chunk...., took 13.884 second\n",
      "inserted another chunk...., took 13.870 second\n",
      "inserted another chunk...., took 13.931 second\n",
      "inserted another chunk...., took 13.947 second\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_194497/3378474225.py:6: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = next(df_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserted another chunk...., took 13.757 second\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_194497/3378474225.py:6: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = next(df_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserted another chunk...., took 13.544 second\n",
      "inserted another chunk...., took 13.886 second\n",
      "inserted another chunk...., took 14.106 second\n",
      "inserted another chunk...., took 13.995 second\n",
      "inserted another chunk...., took 13.887 second\n",
      "inserted another chunk...., took 13.835 second\n",
      "inserted another chunk...., took 13.897 second\n",
      "inserted another chunk...., took 13.860 second\n",
      "inserted another chunk...., took 13.866 second\n",
      "inserted another chunk...., took 13.789 second\n",
      "inserted another chunk...., took 14.004 second\n",
      "inserted another chunk...., took 13.871 second\n",
      "inserted another chunk...., took 13.865 second\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_194497/3378474225.py:6: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = next(df_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserted another chunk...., took 13.584 second\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_194497/3378474225.py:6: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = next(df_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserted another chunk...., took 13.669 second\n",
      "inserted another chunk...., took 13.925 second\n",
      "inserted another chunk...., took 13.789 second\n",
      "inserted another chunk...., took 13.838 second\n",
      "inserted another chunk...., took 14.004 second\n",
      "inserted another chunk...., took 13.806 second\n",
      "inserted another chunk...., took 13.821 second\n",
      "inserted another chunk...., took 13.815 second\n",
      "inserted another chunk...., took 13.876 second\n",
      "inserted another chunk...., took 13.915 second\n",
      "inserted another chunk...., took 13.926 second\n",
      "inserted another chunk...., took 13.893 second\n",
      "inserted another chunk...., took 13.804 second\n",
      "inserted another chunk...., took 14.127 second\n",
      "inserted another chunk...., took 13.968 second\n",
      "inserted another chunk...., took 14.116 second\n",
      "inserted another chunk...., took 14.089 second\n",
      "inserted another chunk...., took 13.969 second\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_194497/3378474225.py:6: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = next(df_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserted another chunk...., took 13.577 second\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_194497/3378474225.py:6: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = next(df_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserted another chunk...., took 13.538 second\n",
      "inserted another chunk...., took 14.039 second\n",
      "inserted another chunk...., took 13.960 second\n",
      "inserted another chunk...., took 13.899 second\n",
      "inserted another chunk...., took 14.065 second\n",
      "inserted another chunk...., took 14.301 second\n",
      "inserted another chunk...., took 14.074 second\n",
      "inserted another chunk...., took 13.958 second\n",
      "inserted another chunk...., took 14.104 second\n",
      "inserted another chunk...., took 13.941 second\n",
      "inserted another chunk...., took 13.938 second\n",
      "inserted another chunk...., took 14.063 second\n",
      "inserted another chunk...., took 14.030 second\n",
      "inserted another chunk...., took 14.020 second\n",
      "inserted another chunk...., took 13.911 second\n",
      "inserted another chunk...., took 14.029 second\n",
      "inserted another chunk...., took 13.977 second\n",
      "inserted another chunk...., took 13.963 second\n",
      "inserted another chunk...., took 14.023 second\n",
      "inserted another chunk...., took 13.856 second\n",
      "inserted another chunk...., took 13.848 second\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_194497/3378474225.py:6: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = next(df_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserted another chunk...., took 13.424 second\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_194497/3378474225.py:6: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = next(df_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserted another chunk...., took 13.901 second\n",
      "inserted another chunk...., took 13.915 second\n",
      "inserted another chunk...., took 13.961 second\n",
      "inserted another chunk...., took 13.963 second\n",
      "inserted another chunk...., took 13.890 second\n",
      "inserted another chunk...., took 13.935 second\n",
      "inserted another chunk...., took 13.972 second\n",
      "inserted another chunk...., took 14.010 second\n",
      "inserted another chunk...., took 14.264 second\n",
      "inserted another chunk...., took 13.878 second\n",
      "inserted another chunk...., took 14.035 second\n",
      "inserted another chunk...., took 14.826 second\n",
      "inserted another chunk...., took 13.911 second\n",
      "inserted another chunk...., took 13.941 second\n",
      "inserted another chunk...., took 13.874 second\n",
      "inserted another chunk...., took 14.097 second\n",
      "inserted another chunk...., took 14.266 second\n",
      "inserted another chunk...., took 16.064 second\n",
      "inserted another chunk...., took 14.732 second\n",
      "inserted another chunk...., took 15.537 second\n",
      "inserted another chunk...., took 13.824 second\n",
      "inserted another chunk...., took 13.814 second\n",
      "inserted another chunk...., took 14.033 second\n",
      "inserted another chunk...., took 13.848 second\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_194497/3378474225.py:6: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = next(df_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserted another chunk...., took 13.237 second\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_194497/3378474225.py:6: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = next(df_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserted another chunk...., took 13.870 second\n",
      "inserted another chunk...., took 13.902 second\n",
      "inserted another chunk...., took 13.810 second\n",
      "inserted another chunk...., took 13.875 second\n",
      "inserted another chunk...., took 13.813 second\n",
      "inserted another chunk...., took 13.732 second\n",
      "inserted another chunk...., took 13.880 second\n",
      "inserted another chunk...., took 13.987 second\n",
      "inserted another chunk...., took 13.841 second\n",
      "inserted another chunk...., took 13.839 second\n",
      "inserted another chunk...., took 13.796 second\n",
      "inserted another chunk...., took 13.853 second\n",
      "inserted another chunk...., took 13.789 second\n",
      "inserted another chunk...., took 13.835 second\n",
      "inserted another chunk...., took 13.796 second\n",
      "inserted another chunk...., took 13.988 second\n",
      "inserted another chunk...., took 13.818 second\n",
      "inserted another chunk...., took 13.817 second\n",
      "inserted another chunk...., took 13.819 second\n",
      "inserted another chunk...., took 13.836 second\n",
      "inserted another chunk...., took 13.819 second\n",
      "inserted another chunk...., took 13.799 second\n",
      "inserted another chunk...., took 13.875 second\n",
      "inserted another chunk...., took 13.794 second\n",
      "inserted another chunk...., took 14.063 second\n",
      "inserted another chunk...., took 13.853 second\n",
      "inserted another chunk...., took 13.935 second\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_194497/3378474225.py:6: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = next(df_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserted another chunk...., took 13.683 second\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_194497/3378474225.py:6: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = next(df_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserted another chunk...., took 13.504 second\n",
      "inserted another chunk...., took 13.856 second\n",
      "inserted another chunk...., took 13.898 second\n",
      "inserted another chunk...., took 13.847 second\n",
      "inserted another chunk...., took 13.834 second\n",
      "inserted another chunk...., took 13.847 second\n",
      "inserted another chunk...., took 13.890 second\n",
      "inserted another chunk...., took 14.173 second\n",
      "inserted another chunk...., took 13.906 second\n",
      "inserted another chunk...., took 13.971 second\n",
      "inserted another chunk...., took 13.939 second\n",
      "inserted another chunk...., took 13.883 second\n",
      "inserted another chunk...., took 13.896 second\n",
      "inserted another chunk...., took 13.856 second\n",
      "inserted another chunk...., took 13.859 second\n",
      "inserted another chunk...., took 13.831 second\n",
      "inserted another chunk...., took 14.098 second\n",
      "inserted another chunk...., took 13.836 second\n",
      "inserted another chunk...., took 13.849 second\n",
      "inserted another chunk...., took 13.941 second\n",
      "inserted another chunk...., took 13.880 second\n",
      "inserted another chunk...., took 13.966 second\n",
      "inserted another chunk...., took 13.733 second\n",
      "inserted another chunk...., took 14.046 second\n",
      "inserted another chunk...., took 13.821 second\n"
     ]
    }
   ],
   "source": [
    "# for inserting all chunks to our table we use loop \n",
    "\n",
    "while True:\n",
    "    t_start = time()\n",
    "    \n",
    "    df = next(df_iter)\n",
    "    \n",
    "    df.tpep_pickup_datetime = pd.to_datetime(df.tpep_pickup_datetime)\n",
    "    df.tpep_dropoff_datetime = pd.to_datetime(df.tpep_dropoff_datetime)\n",
    "    \n",
    "    df.to_sql(name='yellow_taxi_data', con=engine, if_exists='append')\n",
    "    \n",
    "    t_end = time()\n",
    "#     to see how the process is going we do print\n",
    "    print('inserted another chunk...., took %.3f second' % (t_end - t_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d336eb8a",
   "metadata": {},
   "source": [
    "# this is the end of video 1.2.2 - ingesting ny taxi data to postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2783a4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1- we runned postgres using docker\n",
    "# 2- we runned it locally\n",
    "# 3- we are able to connect to this database\n",
    "# 4- we took a look to the data we use throughout the course\n",
    "# 5- we started to put this data to our postgres database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ae4586",
   "metadata": {},
   "source": [
    "# in next video we will use pgadmin to connect to our database which is more convenient than using pgcli   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
